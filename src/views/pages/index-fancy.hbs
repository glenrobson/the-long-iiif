---
title: An Introduction to IIIF
pageHeading: An Introduction to IIIF
---
{{#extend "simple"}}
    {{#content "below-header"}}
        
    {{/content}}
    {{#content "before-main"}}
        {{> 'start' }}
    {{/content}}
    {{#content "main"}}
        
        {{> '01-abstract' }}
        {{> '02-descriptive-semantics' }}
        {{> '03-presentation-semantics' }}
        {{> '04-the-human-presentation-api' }}
        {{> '05-pathways' }}
        {{> '06-surrogate' }}
        {{> '07-standards' }}
        {{> '08-presentationapi' }}

        <div class="static-content">
            <div class="copy">
                <h2>Manifests and Canvases</h2>

                <p>How does the Presentation API work?</p>
                <img src="http://iiif.io/api/presentation/2.1/img/objects.png" width="200"
                        style="float:left;margin-right:15px;" />

                <div class="ablock">

                    <h3>Manifests for things</h3>
                    <p>The Presentation API describes “just enough metadata to drive a remote
                        viewing experience”. This metadata is a <b>IIIF Manifest</b>. The Manifest
                        represents the thing. A book. A painting. A film. A sculpture. An opera. A
                        long-playing record. A manuscript. A map. An aural history field recording.
                        A videocassette of a public information film. A laboratory notebook. A
                        diary. All of these things would be represented by a IIIF Manifest. A
                        manifest is what you load into a viewer or use to generate a web page. If
                        the object the manifest represents is a photograph, there might only be one
                        conceptually distinct view of it that we wish to convey via the Presentation
                        API, to end up on a user's screen. For many objects there is more than one
                        view. Even for a painting, it might be important to include the back of the
                        canvas frame. And for books, manuscripts and much archive material, each
                        page, leaf, folio or sheet is one or two separate views - we can't look at
                        all of them at once, the model conveys them as a sequence of distinct views.
                        Depending on how the book has been captured and how we want to model it, we
                        might have one view per page, or one view per double page spread, and extra
                        views for inserts or supplementatry material.</p>

                    <h3>Canvases for views</h3>
                    <p>
                        These views are represented by <b>Canvases</b>. A Manifest contains one or
                        more <b>Sequences</b> of <b>Canvases</b>.

                        A canvas is not the same as an image. The canvas is an abstraction, a
                        virtual container for content. It's analogous to a PowerPoint slide; an
                        initially empty container, onto which we "paint" content. In coming up with
                        a model for providing a sequence of images to a book reading application, or
                        for viewing paintings, the concept of a canvas may seem like an extra layer
                        of complexity. It's not much more complicated to do it this way, but it is
                        much more flexible and powerful.</p>

                    <img src="https://camo.githubusercontent.com/5fcc89a4144e15741d7c37863f4ff8d01602f4ab/687474703a2f2f746f6d6372616e652e6769746875622e696f2f736372617463682f696d672f626162656c2d63616e7661732e706e67" />
                    <p><i>The canvas is the abstract space; we provide an image to paint the
                        canvas</i></p>

                    <p>The Canvas keeps the content separate from the conceptual model of the page
                        of the book, or the painting, or the movie. The content can be images,
                        blocks of text, video, links to other resources, and the content can be
                        positioned precisely on the canvas. By including a Canvas in a Manifest, you
                        assert a space on which you and others can <b>annotate</b> content. For
                        image-based content the PowerPoint analogy is clear: the Canvas is a 2D
                        rectangular space with an aspect ratio. The height and width properties of a
                        canvas define the aspect ratio and provide a simple coordinate space. This
                        coordinate space allows the creator of the manifest to associate whole or
                        parts of content with whole or parts of canvases, and for anyone else to
                        make their own annotations in that space. This means that you can provide
                        more than one representation of a view. You might have a painting
                        photographed in natural light and in X-ray. You might have a manuscript that
                        was captured to microfilm, and your initial presentation of the material
                        uses images derived from the microfilm. Later, you go back and photograph
                        some of the folios at high resolution, maybe those with illuminations. You
                        can update the content associated with a Canvas, without having to retract
                        the canvas and the other content you might already have associated with it.
                        You may have a manuscript; in IIIF it is represented as a sequence of
                        Canvases, but for some of those Canvases you have no image at all - the page
                        was known to exist, but is now lost. You may still have text content
                        associated with the Canvas - transcriptions from a copy, commentary, or
                        other notes. The fact that for this particular folio you have no
                        photographic representation doesn't stop you modelling it in the Manifest
                        and associating content with it - just not a pictorial representation in
                        this case.</p>
                </div>
                <h3>Annotations for content</h3>
                <p>All association of content with a canvas is done by <b>annotation</b>. The IIIF
                    Presentation API is built on the Open Annotation standard, which has now become
                    the W3C Web Annotation Data Model. At its simplest, the Web Annotation Data
                    Model is a formalised way of linking resources together:</p>

                <p><i>An annotation is considered to be a set of connected resources, typically
                    including a body and target, and conveys that the body is related to the target.
                    The exact nature of this relationship changes according to the intention of the
                    annotation, but the body is most frequently somehow "about" the target. This
                    perspective results in a basic model with three parts, depicted below. The full
                    model supports additional functionality, enabling content to be embedded within
                    the annotation, selecting arbitrary segments of resources, choosing the
                    appropriate representation of a resource and providing styling hints to help
                    clients render the annotation appropriately.</i></p>
                <img class="img-center" src="https://www.w3.org/TR/annotation-model/images/intro_model.png"
                        width="400" />

                <p>A simple annotation might be an association between a page of a manuscript and an
                    article about that page elsewhere on the web. Or, in the context of a bookreader
                    or viewer, it might be a comment on or transcription of a particular part of the
                    page, or the whole page. This notion of annotations as commentary or
                    transcriptions is familiar:</p>

                <img class="img-center" src="assets/img/image-annos.png" />

                <p>But in IIIF, the image itself is one just of the pieces of content annotating the
                    abstract canvas. There may be multiple images, there may be no images at all.
                    This diagram shows that all the content a user ever sees rendered by a viewer -
                    images, text and other content - is associated with the virtual space of the
                    canvas via the mechanism of annotation.</p>

                <img class="img-center" src="assets/img/img-and-canvas-annos.png" />

                <p>IIIF distinguishes between annotations that are for <b>painting</b> on to the
                    canvas - images, transcriptions - and other annotations, that don't necessarily
                    make sense rendered directly onto the virtual space. For example, commentary
                    might be rendered alongside the image in a viewer, not superimposed on top of
                    it, but transcription could be superimposed directly in a layer that can be
                    toggled on and off:

                    <img class="img-center" src="assets/img/transcription.jpg" />
                    <cite>http://wellcomelibrary.org/item/b28769454, manifest:
                        http://wellcomelibrary.org/iiif/b28769454/manifest</cite>

                <p>When you publish a manifest, you publish a sequence of one or more canvases that
                    are almost always accompanied by one or more image annotations - usually just
                    one. Suppose you have a digitised book, the manifest that represents it consists
                    of a sequence of canvases, with image annotations:</p>

                <img class="img-center" src="assets/img/manifest-sequence.png" />

                <p>
                    Although in this initial state each canvas is accompanied in the manifest by
                    just one image annotation, the stage is set for you and others to add more
                    annotations in future. When you add annotations, you might publish them in your
                    manifest alongside the image annotations. When other people annotateyour
                    content, they can't do this directly. But they can still create annotations
                    using the identity and coordinate system you have extablished for your canvas.
                    This allows make annotations on your content for my own private use, or for me
                    to publish them independently and combine them with yout Manifest and its
                    canvases in my own presentation of your material, or even for you to accept my
                    annotations back and incorporate them into your published content.</p>

                <p>The canvas establishes a stage in which the simplest case - one image per canvas
                    - is straightforward, but more complex cases, more complex and interesting
                    associations of content, follow naturally. Suppose a manuscript folio that once
                    looked like this:</p>

                <img class="img-center" src="assets/img/bod-manus-1.png" />

                <p>...was torn up and its various parts scattered. Today, we have images of three
                    surviving parts:</p>

                <div class="center">
                    <img src="assets/img/mtl.png" width="200" style="margin:15px;" />
                    <img src="assets/img/mtr.png" width="200" style="margin:15px;" />
                    <img src="assets/img/mbl.png" width="200" style="margin:15px;" />
                </div>
                <p>We can include a canvas for this missing leaf, and annotate the three parts we do
                    have onto it, as well as providing some commentary about this missing piece:</p>

                <img src="assets/img/fragments.png" />

                <p>Again, the similarity between this and a PowerPoint slide is noticeable. But
                    unlike a Powerpoint slide, the Manifest, the Canvas and all the annotations of
                    content onto it, are interoperable, and part of the web of linked data. We and
                    anyone else can make statements about them, and add to the statements about
                    them, in the web of linked data. And we publish all this information in easy to
                    consume, interopeable API for ourselves and others to view, interact with, and
                    build new interesting things from.</p>

            </div>
        </div>
        <div class="static-content">
            <div class="copy">
                <h2>Canvases and 2D space</h2>
                <p>The IIIF Presentation API isn't just for images. So far we have looked at 2D
                    canvases. The current IIIF Presentation API has supported 2D canvases right from
                    the start. While we can annotate time-based media (audio and video) onto a 2D
                    Canvas in space, in exactly the same way we position images and text onto the
                    canvas using the coordinate system, the current published specification doesn't
                    allow us to annotate images, text, video, audio and other content onto the
                    canvas at a particular point in time, because a Canvas has no duration, no
                    concept of a time dimension to accompany the width and height. If we add a time
                    dimension, it allows us to annotate in both space and time:

                <p>FIRE HERE</p>

                <p>
                    And also, we can have a Canvas that has only a duration, no width or height -
                    onto which we could annotate audio tracks. The same model accomodates this.

                    In the future, the model may also accomodate 3D or 3D time-based media - but the
                    focus for this year is to make the model work well for AV, just as it does for
                    image and text content.
                </p>
            </div>
        </div>
        <div class="static-content">
            <div class="copy">
                <h2>The Image API</h2>
                <p>So far, we have looked at annotating images onto canvases. A manifest contains a
                    sequence of one or more canvases, each of which might have an image and possibly
                    additional content - more images, text annotations, commentary, transcriptions
                    and so on. While single static images are enough to drive a viewing experience,
                    for many objects of cultural heritage having just one image representation
                    available is not very flexible. Typically manuscripts, artworks, maps and to
                    some extent books and archive material are digitised at a very high resolution.
                    We need access to that high resolution to view the detail in an image, but
                    requiring our clients to load multi-mega- or even giga-pixel images just to look
                    at book pages is unreasonable. We need to have a variety of sizes available for
                    different purposes. And ideally, we can choose the regions and sizes we want to
                    use from the image dynamically.</p>
                <p>
                    The Image API specifies a syntax for web requests that lets us ask for images at
                    different sizes and in different formats and qualities. Each image endpoint is a
                    web service that returns new derivative images. We can ask for the full image,
                    or regions of the image. We can rotate, scale, distort, crop and mirror the
                    whole image, or parts of the image. </p>

                <input id="irb1" type="radio" name="imgapi1" data-region="full" data-size="800,"
                        data-rotation="0" data-quality="default" data-format="jpg" />
                <label for="irb1">The whole painting confined to a box 800 pixels wide</label><br />
                <input id="irb2" type="radio" name="imgapi1" data-region="4150,1550,1600,800"
                        data-size="800,400" data-rotation="0" data-quality="default"
                        data-format="jpg" />
                <label for="irb2">A particular rectangular region of the image at a particular
                    size</label><br />
                <input id="irb3" type="radio" name="imgapi1" data-region="4150,1550,1600,800"
                        data-size="600,600" data-rotation="0" data-quality="default"
                        data-format="jpg" />
                <label for="irb3">The same region, distorted to 600 x 600</label><br />
                <input id="irb4" type="radio" name="imgapi1" data-region="4150,1550,1600,800"
                        data-size="!600,600" data-rotation="0" data-quality="default"
                        data-format="jpg" />
                <label for="irb4">The same region, confined to 600 x 600</label><br />
                <input id="irb5" type="radio" name="imgapi1" data-region="4150,1550,1600,800"
                        data-size="!600,600" data-rotation="90" data-quality="default"
                        data-format="jpg" />
                <label for="irb5">...and then rotated</label><br />
                <input id="irb6" type="radio" name="imgapi1" data-region="4150,1550,1600,800"
                        data-size="!600,600" data-rotation="!0" data-quality="default"
                        data-format="jpg" />
                <label for="irb6">...or mirrored</label><br />
                <input id="irb7" type="radio" name="imgapi1" data-region="full" data-size="800,"
                        data-rotation="0" data-quality="gray" data-format="jpg" />
                <label for="irb7">The whole painting in grayscale</label><br />

                <div id="imgApiUrl">

                    https://(image-identifier)
                    / <input type="text" style="width:10em" disabled value="region" />
                    / <input type="text" style="width:6em" disabled value="size" />
                    / <input type="text" style="width:4em" disabled value="rotation" />
                    / <input type="text" style="width:6em" disabled value="quality" />
                    / .jpg

                    <br />
                    https://(image-identifier)
                    / <input type="text" class="imgapipart" id="imgRegion" style="width:10em" />
                    / <input type="text" class="imgapipart" id="imgSize" style="width:6em" />
                    / <input type="text" class="imgapipart" id="imgRotation" style="width:4em" />
                    / <input type="text" class="imgapipart" id="imgQuality" style="width:6em" />
                    / .jpg <input type="button" id="imgApiGo" value="go.." />
                </div>

                <img id="imgApiTarget"
                        data-info="https://dlcs.io/iiif-img/3/2/04fbbb28-d5a7-4408-b7da-800c4e65eda3"
                        src="https://dlcs.io/iiif-img/3/2/04fbbb28-d5a7-4408-b7da-800c4e65eda3/full/800,/0/default.jpg" />

                <script>
                    $(function () {
                        $("input[type=radio][name=imgapi1]").change(function () {
                            var $img = $("#imgApiTarget");
                            var region = $(this).attr("data-region");
                            var size = $(this).attr("data-size");
                            var rotation = $(this).attr("data-rotation");
                            var quality = $(this).attr("data-quality");
                            var src = $img.attr("data-info") + "/" + region + "/" + size + "/" + rotation + "/" + quality + ".jpg";
                            $("#imgRegion").val(region);
                            $("#imgSize").val(size);
                            $("#imgRotation").val(rotation);
                            $("#imgQuality").val(quality);
                            $img.attr("src", src);
                        });
                        $("#irb1").click();

                        $("#imgApiGo").click(function () {
                            var $img = $("#imgApiTarget");
                            var src = $img.attr("data-info") + "/" + $("#imgRegion").val() + "/" + $("#imgSize").val() + "/" + $("#imgRotation").val() + "/" + $("#imgQuality").val() + ".jpg";
                            $img.attr("src", src);
                        });
                    });
                </script>

                <p>
                    If you provide a IIIF Image API endpoint, you are providing a service that
                    viewers can call to get images. This might be a single static image - you could
                    use the image service to link to an image that’s just the right size for your
                    blog post, using appropriate values in the URL as in the examples above and
                    avoid having to make any new derivatives yourself. This use of the Image API
                    works with any browser that supports images.</p>
                <p>
                    Or it might be more complex - a deep zoom viewer works by making many requests
                    for small regions of the image, known as tiles. In the following images, we see
                    an exploded view of the tiles the client is requesting from the Image API. It is
                    asking for small square regions at a particular size and zoom level. Just as you
                    don’t need to load the whole world into Google Maps to view your neighbourhood
                    at street level detail, a deep zoom client doesn’t need to load an enormous
                    image for you to view a particular part of it at the highest resolution. IIIF
                    enables images of Gigapixel size to be viewed in great detail while keeping
                    bandwidth use to the minimum, because the server is able to return small, fast
                    tiles from which the viewer can compose the scene.
                </p>
                <img src="assets/img/exploded.png" />
                <p>You can experiment with tiles using <a
                        href="http://tomcrane.github.io/presentations/tile-exploder.html">this
                    tool</a>.
                </p>

                <p>
                    if you have a IIIF Image API endpoint available for each of your images, you
                    have flexibility for how you and others use your image resources. You could, for
                    example, have a static image that turns into a deep zoom image when clicked.
                    Although the image below is a regular image tag that works in all browsers,
                    there is some JavaScript enhancement that turns it into a deep zoom image when
                    clicked. In this case it uses the OpenSeadragon library which is used for deep
                    zoom by viewers such as the Universal Viewer and Mirador:</p>

                <script src="https://tomcrane.github.io/iiif-img-tag/js/jquery.iiif-image-tag.js"></script>
                <script>
                    $(function () {
                        $(".iiif-image").iiifImage();
                    });
                </script>

                <img class="iiif-image"
                        src="https://dlcs.io/iiif-img/2/1/e75d37c5-40a1-48a4-b61b-52ac7aa26849/full/500,/0/default.jpg" />

                <p>This technique can be extended to build the simplest of manifest viewers:</p>

                <div class="thumbset">
                    <img class="iiif-image"
                            src="https://dlcs.io/iiif-img/wellcome/1/3bde01c5-95fc-4c4c-aaaa-8a10f9a0ffc8/full/125,200/0/default.jpg" />
                    <img class="iiif-image"
                            src="https://dlcs.io/iiif-img/wellcome/1/9ba139ed-578c-483c-bc71-f093bcd357f5/full/125,200/0/default.jpg" />
                    <img class="iiif-image"
                            src="https://dlcs.io/iiif-img/wellcome/1/7c9b7817-e519-44ef-a724-487a00599fc5/full/125,200/0/default.jpg" />
                    <img class="iiif-image"
                            src="https://dlcs.io/iiif-img/wellcome/1/e33add4e-6fe8-43de-8aed-f7c128d051ac/full/125,200/0/default.jpg" />
                    <img class="iiif-image"
                            src="https://dlcs.io/iiif-img/wellcome/1/b763a277-0067-4398-9ad5-8b946fbe2533/full/125,200/0/default.jpg" />
                    <img class="iiif-image"
                            src="https://dlcs.io/iiif-img/wellcome/1/aea8e1ac-b1ba-41cd-b56f-b1acae113de0/full/125,200/0/default.jpg" />
                    <img class="iiif-image"
                            src="https://dlcs.io/iiif-img/wellcome/1/80890c4d-d8d0-4f69-b6d9-ebc411e17c0a/full/125,200/0/default.jpg" />
                    <img class="iiif-image"
                            src="https://dlcs.io/iiif-img/wellcome/1/96654cec-c4ef-44fe-9e30-8c342767fbdd/full/125,200/0/default.jpg" />
                    <img class="iiif-image"
                            src="https://dlcs.io/iiif-img/wellcome/1/ff64989e-4096-4054-9ef1-14ac3d7f1afe/full/125,200/0/default.jpg" />
                </div>

                <p>Another use of an image server is for generating responsive images without having
                    to create multiple derivatives in an image editing application. The following is
                    a contrived example:</p>
                <pre>   
                    <code class="language-html">
&lt;picture&gt;
    &lt;source media="(min-width: 1600px)" srcset="https://dlcs.io/.../120,850,2100,2000/1600,/0/default.jpg"&gt;
    &lt;source media="(min-width: 700px)"  srcset="https://dlcs.io/.../250,850,1950,2000/1000,/0/default.jpg"&gt;
    &lt;source media="(min-width: 400px)"  srcset="https://dlcs.io/.../250,850,900,1000/500,/0/default.jpg"&gt;
    &lt;img alt="example image"               src="https://dlcs.io/.../250,850,900,1000/320,/0/default.jpg"&gt;
&lt;/picture&gt;
                    </code>
</pre>

                <p>See more at <a href="https://tomcrane.github.io/iiif-img-tag/">image tag</a></p>

                <p>See extracted Dublin tool at <a href="TODO">here</a></p>
            </div>
        </div>
        <div class="static-content">
            <div class="copy">
                <h2>Combining deep zoom tile sources and Canvases</h2>

                <p>Once scenario in which multiple images annotate the same canvas is when there is
                    a choice of views of an object. In the following examples, two different user
                    interface treatments are offered for the choice between the natural light and
                    the x-ray views of this painting.</p>

                <h3>Side by side using Leaflet.js</h3>
                <iframe sandbox="allow-popups allow-scripts allow-forms allow-same-origin"
                        src="dee-sbs.html" marginwidth="0" marginheight="0"
                        style="height:500px;width:800px;" scrolling="no"></iframe>
                <p><a href="dee-sbs.html" target="_blank">(open in new window)</a></p>

                <h3>One at a time using OpenSeadragon</h3>

                <div id="deeOsd1" style="width:800px; height:500px"></div>

                <script>
                    var deeOsdViewer = OpenSeadragon({
                        id: "deeOsd1",
                        prefixUrl: "openseadragon/images/"
                    });
                    deeOsdViewer.addTiledImage({ tileSource: "https://dlcs.io/iiif-img/3/2/04fbbb28-d5a7-4408-b7da-800c4e65eda3/info.json" });
                    deeOsdViewer.addTiledImage({
                        tileSource: "https://dlcs.io/iiif-img/3/2/8034eb5b-9c90-4471-ad68-52124232ec0c/info.json",
                        opacity: 0
                    });

                    $(document).ready(function () {
                        $("input[type='radio']").click(function () {

                            deeOsdViewer.world.getItemAt(0).setOpacity(0);
                            deeOsdViewer.world.getItemAt(1).setOpacity(0);
                            var checked = $(this).is(":checked");
                            var index = $(this).attr("data-index");
                            var ti = deeOsdViewer.world.getItemAt(index);
                            console.log(index);
                            if (checked) {
                                ti.setOpacity(1);
                            }
                        });
                    });
                </script>

                <p>
                    <input type="radio" name="choices" class="choice" data-index="0" checked
                            id="c0" /><label for="c0">Natural light</label><br />
                    <input type="radio" name="choices" class="choice" data-index="1"
                            id="c1" /><label for="c1">X-ray</label>
                </p>
            </div>
            </div>


        {{> 'more-iiif-stories' }}













    {{/content}}
{{/extend}}
